{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxfsI1cjhhTejm9bXdk9F8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The **Machine Learning Model Deployment** project will demonstrate the proficiency in using a Jupyter Notebook to take a machine learning model from training to deployment. The following actions will be involved in this project:\n",
        "\n",
        "**Data Preprocessing:** Load and clean the data.\n",
        "\n",
        "**Model Training:** Train a machine learning model on the processed data.\n",
        "\n",
        "**Model Serialization:** Save the trained model so that it can be used later for predictions.\n",
        "\n",
        "**Model Deployment:** Create a simple web API using Flask within the Jupyter Notebook to serve predictions.\n"
      ],
      "metadata": {
        "id": "zlmyP5eZt_yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "\n",
        "!pip install flask flask-ngrok scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n"
      ],
      "metadata": {
        "id": "9hlFl6kzu86F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Spliting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Displaying the shape of the dataset\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "qXTsaKk8vJS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "O-MKWAB1vLp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving trained model\n",
        "model_filename = 'iris_model.pkl'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")"
      ],
      "metadata": {
        "id": "lRXCNVxQvNwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Deployment!\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Use ngrok to allow external access to the Flask app\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(model_filename)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json(force=True)\n",
        "    input_data = np.array(data['data'])\n",
        "    prediction = model.predict(input_data)\n",
        "    output = {'prediction': prediction.tolist()}\n",
        "    return jsonify(output)\n",
        "\n",
        "# Run app\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "pfdxMLo2vZqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the API\n",
        "\n",
        "import requests\n",
        "\n",
        "# Sample input data\n",
        "sample_data = {\n",
        "    'data': [[5.1, 3.5, 1.4, 0.2]]\n",
        "}\n",
        "\n",
        "# Sending POST request to the API\n",
        "response = requests.post('http://localhost:5000/predict', json=sample_data)\n",
        "\n",
        "# Display response\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "id": "gIfRleIBvoOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}